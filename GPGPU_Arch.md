# General-Purpose Graphics Processor Architecture

Tor M. Aamodt 

Wilson Wai Lun Fung 

Timothy G. Rogers

翻译人员：胡洧铭

邮箱：huwm1@shanghaitech.edu.cn

### 摘要

​	图形处理器单元（GPU）最初是为支持视频游戏而开发的，现在越来越多地用于machine learning、挖掘加密货币等通用（非图形）应用程序中。通过将较大比例的硬件资源专用于计算，GPU可以实现比中央处理单元（CPU）更高的性能和效率。此外，与特定领域的加速器相比，它们的通用可编程性使得现代GPU吸引软件开发人员。本书为那些对研究支持通用计算的GPU架构感兴趣的人提供了介绍。它汇集了当前在各种资源中发现的信息。该书作者领导了GPGPU-Sim模拟器的开发，该模拟器广泛用于GPU架构的学术研究中。

​	本书的第一章介绍了GPU的基本硬件结构，并简要概述了它们的历史。第2章总结了与本书其余部分相关的GPU编程模型。第3章探讨了GPU计算核心的体系结构。第4章探讨了GPU内存系统的体系结构。在描述了现有系统的体系结构之后，第3章和第4章概述了相关研究。第5章总结了影响计算核心和内存系统的跨领域研究。

​	对于那些希望了解用于加速通用应用程序的图形处理器单元（GPU）的体系结构的人员，以及那些想要获得这方面快速发展的研究介绍，以探索如何改善这些GPU的体系结构的人，这本书应该提供宝贵的资源。

### 关键字

GPGPU, 计算机体系结构

### 前言

​	本书供那些希望了解图形处理器单元（GPU）架构以及希望了解不断发展的研究以改进其设计的人员。本书也假定读者熟悉诸如流水线和缓存之类的计算机体系结构概念，并且对进行与GPU体系结构相关的研究和/或开发感兴趣。此类工作往往侧重于不同设计之间的trade-off，因此编写本书的目的是提供对此类trade-off的见解，以便读者可以避免通过反复试验来学习经验丰富的设计师已经知道的知识。

​	为了帮助实现这一目标，该书将目前在各种不同来源（例如专利，产品文档和研究论文）中发现的许多相关信息汇总为一种资源。希望这将有助于减少学生或从业人员因刚开始他们自己的研究所花费的时间，并使其高效。

​	尽管本书涵盖了当前GPU设计的各个方面，但它也试图“综合”已发表的研究。一部分是出于必要性，因为供应商对特定GPU产品的微体系结构所知甚少。在描述“基准” GPGPU架构时，该书依靠已发表的产品说明（期刊，白皮书，手册），在某些情况下还包括专利说明。专利中发现的细节可能与实际产品的微体系结构大不相同。在某些情况下，微基准研究为研究人员澄清了一些细节，但在其他情况下，我们的基准则代表了基于公开信息的“最佳猜测”。尽管如此，我们认为这将是有帮助的，因为我们的重点是理解已经研究过的architecture trade-off，或是在将来的研究中可能会引起兴趣的方向。

​	本书的多个部分着重于总结近年来关于改进GPU体系结构主题的研究论文。近年来，随着该主题的广泛流行，本书中涉及的内容太多了。因此，我们不得不对what to cover and what to leave out做出艰难的选择。

Tor M. Aamodt, Wilson Wai Lun Fung, and Timothy G. Rogers
April 2018

### 致谢

​	我们要感谢我们的家人在编写本书时所给予的支持。此外，我们还要感谢我们的出版商Michael Morgan和编辑Margaret  Martonosi，感谢他们在本书出版时表现出的极大耐心。我们还要感谢Carole-Jean Wu, Andreas Moshovos, Yash  Ukidave, Aamir Raihan和Amruth Sandhupatla对本书的早期草稿提供了详细的反馈。最后, 我们感谢Mark  Hill分享了他对撰写综合讲座的策略的想法以及针对该书的具体建议。

Tor M. Aamodt, Wilson Wai Lun Fung, and Timothy G. Rogers
April 2018

## 第一章

### Introduction

​	本书探讨了图形处理器单元（GPU）的硬件设计。最初引入 GPU 是为了实现实时渲染，重点是视频游戏。如今，从智能手机，笔记本电脑，数据中心到超级计算机的各个地方都可以找到 GPU。确实，对Apple  A8应用处理器的分析表明，与中央处理器单元（A8H）相比，它对集成GPU的投入更多。对更逼真的图形渲染的需求是GPU创新的最初动力 [Montrym and  Moreton，2005] 。尽管图形加速仍然是其主要目的，但GPU越来越多地支持非图形计算。今天受到关注的一个突出例子是越来越多地使用GPU来开发和部署机器学习系统[NVIDIA  Corp.，2017] 。因此，本书的重点是与提高非图形应用程序的性能和能效有关的功能。

​	本介绍性章节简要介绍了GPU。我们从第1.1节开始，考虑更多种类的计算加速器的动机，以了解GPU与其他选项的比较。然后，在第1.2节中，我们提供了当代GPU硬件的快速概述。最后，第1.4节提供了本书其余部分的路线图。

### 1.1 THE LANDSCAPE OF COMPUT ATIONACCELERATORS

​	

### 3.3  THREE-LOOP APPROXIMATION

​	如前所述，为了隐藏较长的内存延迟，每个内核必须支持多个线程束 (warp) ，并且为了支持线程束之间的循环切换，必须有一个大的寄存器文件，其中包含每个正在执行的线程束的独立物理寄存器。例如，这种寄存器 (register) 在NVIDIA最近的GPU架构 (例如Kepler, Maxwell, and Pascal架构) 中含256KB。现在，SRAM 存储器的面积与端口数量成正比。一个寄存器堆 (register file) 的简单实现要求每个周期内每个指令的每个操作数有一个端口。减少寄存器堆面积的一种方法是使用多组单端口存储器 (single-ported memories) 模拟大量端口。虽然通过将这些banks暴露给指令集架构可能实现这种效果，但在一些GPU设计中，它似乎使用了一种称为操作数收集器 (operand collector) 的结构 [Coon等人, 2009; Lindholm等人, 2008b; Lui等人, 2008] ，它用一种更透明的方式来实现这一效果。操作数收集器有效地形成了第三个调度循环，如下所述。

​	为了更好地理解由操作数收集器解决的问题，首先考虑图3.12，它展示了一种简单的微体系结构，用于提供增加的寄存器堆的带宽。这张图显示了GPU指令管道的寄存器读取阶段，其中寄存器文件由四个单端口的逻辑寄存器组组成。在实际中，由于寄存器堆非常大，每个logical bank 可能进一步分解为更大数量的 physical bank (图中未显示) 。 logical bank 通过交叉开关连接到暂存寄存器 (标记为“流水线寄存器”) ，暂存寄存器在将源操作数传递到 SIMD 执行单元之前缓存源操作数。仲裁器 (Arbiter) 控制对 individual banks 的访问，并通过交叉开关 （crossbar） 将结果路由到适当的暂存寄存器。

<img src="D:\STU\2021-Spring\Core Course\GPGPU\Image\1614392491(1).jpg" alt="1614392491(1)" style="zoom: 40%;" />

​	图3.13显示了每个 warp 寄存器到 logical bank 的简单布局。在此图中，来自warp 0 (w0) 的寄存器 r0 存储在存储体0的第一个位置，来自warp  0的寄存器 r1 存储在存储体1的第一个位置，依此类推。如果计算所需的寄存器数量大于 logical bank 的数量，则分配会自动完成。例如，warp 0 的寄存器 r4 存储在 bank 0 的第二个位置。

<img src="C:\Users\50683\AppData\Roaming\Typora\typora-user-images\image-20210227102912273.png" alt="image-20210227102912273" style="zoom: 50%;" />

​	图3.14显示了一个时序示例，突出显示了这种微体系结构如何损害性能。该示例涉及顶部显示的两条指令 (i1, i2) 。第一条指令 i1 是从寄存器 r5、r4 和 r6 读取的多相加操作，寄存器 r5、r4 和 r6 分配在存储体1、0和2中 (由图中的下标表示) 。第二条指令i2是从寄存器r5和r1读取的加法指令，两者都分配在存储体1中。图的中间部分显示了指令发出的顺序。在周期 0 上，warp 3 发出指令 i1 ，在周期 1上，warp 0 发出指令 i2，在周期 4 上，warp 1 在由于如下所述的 bank conflict 引起的延迟之后发出指令 i2 。图的底部示出了不同指令对不同 banks 的访问时序。在周期1，来自warp  3的指令 i1 能够在周期1读取其所有三个源寄存器，因为它们映射到不同的 logical banks 。然而，在周期2，来自 warp 0 的指令 i2 只能读取其两个源寄存器中的一个，因为两者都映射到 bank 1。在周期3，该指令的第二个源寄存器与指令 i1 从warp 3 的写回并行读取。在周期4，来自 warp 1 的指令 i2 能够读取其第一个源操作数，但不能读取第二个源操作数，因为它们都映射到 bank 1。在周期5，来自 warp 1 的指令 i2 的第二个源操作数被阻止从寄存器堆中读取，因为 bank 已经被warp  0 先前发布的指令 i2 的更高优先级写回所访问。最后，在周期6，从寄存器堆中读取来自 warp 1 的 i2 的第二个源操作数。总之，三条指令需要六个周期才能完成对其源寄存器的读取，在此期间，许多 bank 不会被访问。

​	<img src="C:\Users\50683\AppData\Roaming\Typora\typora-user-images\image-20210227113035131.png" alt="image-20210227113035131" style="zoom: 50%;" />

​	

#### 3.3.1  OPERAND COLLECTOR