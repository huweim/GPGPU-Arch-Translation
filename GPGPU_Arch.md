# General-Purpose Graphics Processor Architecture

Tor M. Aamodt 

Wilson Wai Lun Fung 

Timothy G. Rogers

翻译人员：胡洧铭

邮箱：huwm1@shanghaitech.edu.cn

### 摘要

​	图形处理器单元（GPU）最初是为支持视频游戏而开发的，现在越来越多地用于machine learning、挖掘加密货币等通用（非图形）应用程序中。通过将较大比例的硬件资源专用于计算，GPU可以实现比中央处理单元（CPU）更高的性能和效率。此外，与特定领域的加速器相比，它们的通用可编程性使得现代GPU吸引软件开发人员。本书为那些对研究支持通用计算的GPU架构感兴趣的人提供了介绍。它汇集了当前在各种资源中发现的信息。该书作者领导了GPGPU-Sim模拟器的开发，该模拟器广泛用于GPU架构的学术研究中。

​	本书的第一章介绍了GPU的基本硬件结构，并简要概述了它们的历史。第2章总结了与本书其余部分相关的GPU编程模型。第3章探讨了GPU计算核心的体系结构。第4章探讨了GPU内存系统的体系结构。在描述了现有系统的体系结构之后，第3章和第4章概述了相关研究。第5章总结了影响计算核心和内存系统的跨领域研究。

​	对于那些希望了解用于加速通用应用程序的图形处理器单元（GPU）的体系结构的人员，以及那些想要获得这方面快速发展的研究介绍，以探索如何改善这些GPU的体系结构的人，这本书应该提供宝贵的资源。

### 关键字

GPGPU, 计算机体系结构

### 前言

​	本书供那些希望了解图形处理器单元（GPU）架构以及希望了解不断发展的研究以改进其设计的人员。本书也假定读者熟悉诸如流水线和缓存之类的计算机体系结构概念，并且对进行与GPU体系结构相关的研究和/或开发感兴趣。此类工作往往侧重于不同设计之间的trade-off，因此编写本书的目的是提供对此类trade-off的见解，以便读者可以避免通过反复试验来学习经验丰富的设计师已经知道的知识。

​	为了帮助实现这一目标，该书将目前在各种不同来源（例如专利，产品文档和研究论文）中发现的许多相关信息汇总为一种资源。希望这将有助于减少学生或从业人员因刚开始他们自己的研究所花费的时间，并使其高效。

​	尽管本书涵盖了当前GPU设计的各个方面，但它也试图“综合”已发表的研究。一部分是出于必要性，因为供应商对特定GPU产品的微体系结构所知甚少。在描述“基准” GPGPU架构时，该书依靠已发表的产品说明（期刊，白皮书，手册），在某些情况下还包括专利说明。专利中发现的细节可能与实际产品的微体系结构大不相同。在某些情况下，微基准研究为研究人员澄清了一些细节，但在其他情况下，我们的基准则代表了基于公开信息的“最佳猜测”。尽管如此，我们认为这将是有帮助的，因为我们的重点是理解已经研究过的architecture trade-off，或是在将来的研究中可能会引起兴趣的方向。

​	本书的多个部分着重于总结近年来关于改进GPU体系结构主题的研究论文。近年来，随着该主题的广泛流行，本书中涉及的内容太多了。因此，我们不得不对what to cover and what to leave out做出艰难的选择。

Tor M. Aamodt, Wilson Wai Lun Fung, and Timothy G. Rogers
April 2018

### 致谢

​	我们要感谢我们的家人在编写本书时所给予的支持。此外，我们还要感谢我们的出版商Michael Morgan和编辑Margaret  Martonosi，感谢他们在本书出版时表现出的极大耐心。我们还要感谢Carole-Jean Wu, Andreas Moshovos, Yash  Ukidave, Aamir Raihan和Amruth Sandhupatla对本书的早期草稿提供了详细的反馈。最后, 我们感谢Mark  Hill分享了他对撰写综合讲座的策略的想法以及针对该书的具体建议。

Tor M. Aamodt, Wilson Wai Lun Fung, and Timothy G. Rogers
April 2018

## 第一章

### Introduction

​	本书探讨了图形处理器单元（GPU）的硬件设计。最初引入 GPU 是为了实现实时渲染，重点是视频游戏。如今，从智能手机，笔记本电脑，数据中心到超级计算机的各个地方都可以找到 GPU。确实，对Apple  A8应用处理器的分析表明，与中央处理器单元（A8H）相比，它对集成GPU的投入更多。对更逼真的图形渲染的需求是GPU创新的最初动力 [Montrym and  Moreton，2005] 。尽管图形加速仍然是其主要目的，但GPU越来越多地支持非图形计算。今天受到关注的一个突出例子是越来越多地使用GPU来开发和部署机器学习系统[NVIDIA  Corp.，2017] 。因此，本书的重点是与提高非图形应用程序的性能和能效有关的功能。

​	本介绍性章节简要介绍了GPU。我们从第1.1节开始，考虑更多种类的计算加速器的动机，以了解GPU与其他选项的比较。然后，在第1.2节中，我们提供了当代GPU硬件的快速概述。最后，第1.4节提供了本书其余部分的路线图。

### 1.1 THE LANDSCAPE OF COMPUT ATIONACCELERATORS

​	

### 3.3  THREE-LOOP APPROXIMATION

​	如前所述，为了隐藏较长的内存延迟，每个内核必须支持多个线程束 (warp) ，并且为了支持线程束之间的循环切换，必须有一个大的寄存器文件，其中包含每个正在执行的线程束的独立物理寄存器。例如，这种寄存器 (register) 在NVIDIA最近的GPU架构 (例如Kepler, Maxwell, and Pascal架构) 中含256KB。现在，SRAM 存储器的面积与端口数量成正比。一个寄存器堆 (register file) 的简单实现要求每个周期内每个指令的每个操作数有一个端口。减少寄存器堆面积的一种方法是使用多组单端口存储器 (single-ported memories) 模拟大量端口。虽然通过将这些banks暴露给指令集架构可能实现这种效果，但在一些GPU设计中，它似乎使用了一种称为操作数收集器 (operand collector) 的结构 [Coon等人, 2009; Lindholm等人, 2008b; Lui等人, 2008] ，它用一种更透明的方式来实现这一效果。操作数收集器有效地形成了第三个调度循环，如下所述。

​	为了更好地理解由操作数收集器解决的问题，首先考虑图3.12，它展示了一种简单的微体系结构，用于提供增加的寄存器堆的带宽。这张图显示了GPU指令管道的寄存器读取阶段，其中寄存器文件由四个单端口的逻辑寄存器组组成。在实际中，由于寄存器堆非常大，每个logical bank 可能进一步分解为更大数量的 physical bank (图中未显示) 。 logical bank 通过交叉开关连接到暂存寄存器 (标记为“流水线寄存器”) ，暂存寄存器在将源操作数传递到 SIMD 执行单元之前缓存源操作数。仲裁器 (Arbiter) 控制对 individual banks 的访问，并通过交叉开关 （crossbar） 将结果路由到适当的暂存寄存器。

<img src="D:\STU\2021-Spring\Core Course\GPGPU\Image\1614392491(1).jpg" alt="1614392491(1)" style="zoom: 40%;" />

​	图3.13显示了每个 warp 寄存器到 logical bank 的简单布局。在此图中，来自warp 0 (w0) 的寄存器 r0 存储在存储体0的第一个位置，来自warp  0的寄存器 r1 存储在存储体1的第一个位置，依此类推。如果计算所需的寄存器数量大于 logical bank 的数量，则分配会自动完成。例如，warp 0 的寄存器 r4 存储在 bank 0 的第二个位置。

<img src="C:\Users\50683\AppData\Roaming\Typora\typora-user-images\image-20210227102912273.png" alt="image-20210227102912273" style="zoom: 50%;" />

​	图3.14显示了一个时序示例，突出显示了这种微体系结构如何损害性能。该示例涉及顶部显示的两条指令 (i1, i2) 。第一条指令 i1 是从寄存器 r5、r4 和 r6 读取的多相加操作，寄存器 r5、r4 和 r6 分配在存储体1、0和2中 (由图中的下标表示) 。第二条指令i2是从寄存器r5和r1读取的加法指令，两者都分配在存储体1中。图的中间部分显示了指令发出的顺序。在周期 0 上，warp 3 发出指令 i1 ，在周期 1上，warp 0 发出指令 i2，在周期 4 上，warp 1 在由于如下所述的 bank conflict 引起的延迟之后发出指令 i2 。图的底部示出了不同指令对不同 banks 的访问时序。在周期1，来自warp  3的指令 i1 能够在周期1读取其所有三个源寄存器，因为它们映射到不同的 logical banks 。然而，在周期2，来自 warp 0 的指令 i2 只能读取其两个源寄存器中的一个，因为两者都映射到 bank 1。在周期3，该指令的第二个源寄存器与指令 i1 从warp 3 的写回并行读取。在周期4，来自 warp 1 的指令 i2 能够读取其第一个源操作数，但不能读取第二个源操作数，因为它们都映射到 bank 1。在周期5，来自 warp 1 的指令 i2 的第二个源操作数被阻止从寄存器堆中读取，因为 bank 已经被warp  0 先前发布的指令 i2 的更高优先级写回所访问。最后，在周期6，从寄存器堆中读取来自 warp 1 的 i2 的第二个源操作数。总之，三条指令需要六个周期才能完成对其源寄存器的读取，在此期间，许多 bank 不会被访问。

​	<img src="C:\Users\50683\AppData\Roaming\Typora\typora-user-images\image-20210227113035131.png" alt="image-20210227113035131" style="zoom: 50%;" />

​	

#### 3.3.1  OPERAND COLLECTOR

​	操作数收集器微体系结构 [Lindholm等，2008b] 如图3.15所示。关键的变化是，暂存器已被收集器单元所取代。当每条指令进入寄存器读阶段时，它被分配一个收集器单元。有多个收集器单元，以便多个指令可以重叠读取源操作数，这有助于在单个指令的源操作数之间存在 bank conflict 时提高吞吐量。每个收集器单元都包含用于执行指令所需的所有源操作数的缓冲空间。由于多个指令的源操作数较多，仲裁器更有可能实现更高的 bank-level 并行，以允许并行访问多个寄存器堆 bank 。

​	<img src="D:\STU\2021-Spring\Core Course\GPGPU\Image\1614665705(1).png" alt="1614665705(1)" style="zoom: 60%;" />

​	操作数收集器使用调度来容忍发生的 bank conflict 。这就留下了如何减少 bank conflict 的问题。图3.16说明了一种改进的寄存器布局，Coon等人描述了这种布局有助于减少 bank conflict。其思想是在不同的 bank 中分配来自不同线程束的等效寄存器。例如，在图3.16中，线程束0的寄存器 r0 分配给 bank 0，而线程束 1 的寄存器 r0 分配给  bank 1。这不能解决单个指令的寄存器操作数之间的bank冲突。然而，它在减少来自不同线程束的指令之间的 bank conflict 方面确实有帮助。尤其是当线程束取得相对均匀的进展时(例如，由于循环调度 (round-robin) 或两级调度 [Narasiman等人，2011]，其中取指组中的单个线程束以循环顺序被调度)。

<img src="D:\STU\2021-Spring\Core Course\GPGPU\Image\微信截图_20210302141627.png" alt="微信截图_20210302141627" style="zoom: 67%;" />.

​	图3.17显示了一个时序示例，顶部显示了一系列加法和乘加指令。中间显示了指令发射顺序。从线程束1 到 3 的 i1 的三个实例在周期 0 到 2 发出。来自线程束0的指令 i2 的实例在周期3发出。请注意，add指令写入寄存器r1，对于任何给定的线程束，寄存器 r1 与源寄存器 r5 分配在同一个 bank 中。然而，与图3.13中使用寄存器布局的情况不同，这里不同的线程束访问不同的 bank，这有助于减少一个线程束的写回和读取其他线程束中的源操作数之间的冲突。底部显示操作数收集器导致的 bank level 访问时序。在周期1，来自线程束1的寄存器r2读取 bank 3。在周期4，注意从线程束 1 写回寄存器r1与从线程束 3 读取寄存器 r5 和从线程束 0 读取寄存器 r3 并行进行。

<img src="D:\STU\2021-Spring\Core Course\GPGPU\Image\微信截图_20210302142539.png" alt="微信截图_20210302142539" style="zoom: 50%;" />.

​	到目前为止，操作数收集器的一个微妙的问题是，因为当不同的指令准备发布时，它没有施加任何顺序，它可能允许读后写(WAR)危险[Mishkin等人，2016]。如果操作数收集器中存在来自同一线程束的两条指令，并且第一条指令读取第二条指令将要写入的寄存器，则会发生这种情况。如果第一个指令的源操作和访问遇到重复的存 bank conflict ，那么可以想象，第二条指令可以在第一个寄存器读取(正确的)旧值之前，向寄存器写入一个新值。防止这种WAR危险的一种方法是简单地要求来自同一线程束的指令按照程序顺序离开操作数收集器到执行单元。Mishkin等人[2016]探索了三种低硬件复杂度的潜在解决方案，并评估了它们的性能影响。第一个是提交时释放 warpboard，每个线程束最多允许执行一条指令。不出所料，他们发现这会对性能产生负面影响，在某些情况下会将性能降低近两倍。他们的第二个提议是读取时释放 warp board，它一次只允许一条指令在操作数收集器中收集操作数。该方案导致他们研究的工作负载最多降低10%。最后，为了在操作数收集器中实现指令级并行，他们提出了一种使用小型布隆过滤器 (bloom filter) 来跟踪未完成的寄存器读取的布隆板 (bloomboard) 机制。与允许 WAR 危害的（不正确的）影响相比，这个的影响不到百分之几。另外，Gray 进行的分析表明，NVIDIA的Maxwell GPU引入了一个“读依赖障碍”，该障碍由特殊的“控制指令”管理，可用于避免某些指令的 WAR 危害 (见2.2.1节)。



